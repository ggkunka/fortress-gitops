{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MCP Security Platform - Interactive API Demo\n",
    "\n",
    "This Jupyter notebook provides an interactive walkthrough of the MCP Security Platform APIs.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "1. Ensure the MCP platform is running: `./scripts/codespace-setup.sh`\n",
    "2. Verify services are healthy: `./scripts/test-poc.sh`\n",
    "3. Install required Python packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install httpx requests pandas matplotlib seaborn plotly jupyter ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import httpx\n",
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configure plotting\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"‚úÖ Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîß Configuration and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# API Configuration\n",
    "API_BASE = \"http://localhost:8000\"\n",
    "AUTH_BASE = \"http://localhost:8001\" \n",
    "CORE_BASE = \"http://localhost:8080\"\n",
    "UI_BASE = \"http://localhost:3000\"\n",
    "\n",
    "# Test credentials\n",
    "CREDENTIALS = {\n",
    "    \"username\": \"admin\",\n",
    "    \"password\": \"admin123\"\n",
    "}\n",
    "\n",
    "# HTTP client with timeout\n",
    "client = httpx.Client(timeout=30.0)\n",
    "\n",
    "print(f\"üîó API Gateway: {API_BASE}\")\n",
    "print(f\"üîê Auth Service: {AUTH_BASE}\")\n",
    "print(f\"‚öôÔ∏è Core Service: {CORE_BASE}\")\n",
    "print(f\"üñ•Ô∏è Dashboard: {UI_BASE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üè• Step 1: Service Health Checks\n",
    "\n",
    "Let's verify all services are running and healthy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_service_health(service_url, service_name):\n",
    "    \"\"\"Check health of a service\"\"\"\n",
    "    try:\n",
    "        response = client.get(f\"{service_url}/health\")\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            print(f\"‚úÖ {service_name}: Healthy\")\n",
    "            return True, data\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è {service_name}: Status {response.status_code}\")\n",
    "            return False, {}\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå {service_name}: Error - {str(e)}\")\n",
    "        return False, {}\n",
    "\n",
    "# Check all services\n",
    "services = [\n",
    "    (API_BASE, \"API Gateway\"),\n",
    "    (AUTH_BASE, \"Auth Service\"),\n",
    "    (CORE_BASE, \"Core Service\")\n",
    "]\n",
    "\n",
    "health_results = {}\n",
    "for url, name in services:\n",
    "    healthy, data = check_service_health(url, name)\n",
    "    health_results[name] = {\"healthy\": healthy, \"data\": data}\n",
    "\n",
    "# Create health status visualization\n",
    "health_df = pd.DataFrame([\n",
    "    {\"Service\": name, \"Status\": \"Healthy\" if info[\"healthy\"] else \"Unhealthy\"}\n",
    "    for name, info in health_results.items()\n",
    "])\n",
    "\n",
    "print(\"\\nüìä Service Health Summary:\")\n",
    "print(health_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîê Step 2: Authentication\n",
    "\n",
    "Authenticate with the platform to get a JWT token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def authenticate():\n",
    "    \"\"\"Authenticate and get JWT token\"\"\"\n",
    "    try:\n",
    "        response = client.post(\n",
    "            f\"{AUTH_BASE}/auth/login\",\n",
    "            json=CREDENTIALS,\n",
    "            headers={\"Content-Type\": \"application/json\"}\n",
    "        )\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            token = data.get(\"access_token\")\n",
    "            if token:\n",
    "                print(f\"‚úÖ Authentication successful!\")\n",
    "                print(f\"üé´ Token: {token[:20]}...\")\n",
    "                return token\n",
    "            else:\n",
    "                print(\"‚ö†Ô∏è No token in response, using demo token\")\n",
    "                return \"demo-jwt-token-12345\"\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è Auth failed with status {response.status_code}, using demo token\")\n",
    "            return \"demo-jwt-token-12345\"\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Auth error: {e}, using demo token\")\n",
    "        return \"demo-jwt-token-12345\"\n",
    "\n",
    "# Authenticate and store token\n",
    "jwt_token = authenticate()\n",
    "\n",
    "# Update client with auth headers\n",
    "auth_headers = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"Authorization\": f\"Bearer {jwt_token}\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìÑ Step 3: Load and Upload SBOM\n",
    "\n",
    "Load a sample SBOM with vulnerabilities and upload it to the platform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test SBOM\n",
    "sbom_file = Path(\"tests/poc/data/test-sbom.json\")\n",
    "\n",
    "if sbom_file.exists():\n",
    "    with open(sbom_file) as f:\n",
    "        sbom_data = json.load(f)\n",
    "    \n",
    "    print(\"üìÑ SBOM Loaded Successfully!\")\n",
    "    print(f\"Format: {sbom_data.get('bom_format')}\")\n",
    "    print(f\"Spec Version: {sbom_data.get('spec_version')}\")\n",
    "    print(f\"Components: {len(sbom_data.get('components', []))}\")\n",
    "    print(f\"Vulnerabilities: {len(sbom_data.get('vulnerabilities', []))}\")\n",
    "    \n",
    "    # Display components summary\n",
    "    components_df = pd.DataFrame([\n",
    "        {\n",
    "            \"Name\": comp.get(\"name\"),\n",
    "            \"Version\": comp.get(\"version\"),\n",
    "            \"Type\": comp.get(\"type\"),\n",
    "            \"License\": \", \".join(comp.get(\"licenses\", []))\n",
    "        }\n",
    "        for comp in sbom_data.get(\"components\", [])\n",
    "    ])\n",
    "    \n",
    "    print(\"\\nüì¶ Components Summary:\")\n",
    "    print(components_df.to_string(index=False))\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå Test SBOM file not found!\")\n",
    "    sbom_data = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload SBOM to the platform\n",
    "def upload_sbom(sbom_data):\n",
    "    \"\"\"Upload SBOM to the platform\"\"\"\n",
    "    if not sbom_data:\n",
    "        print(\"‚ùå No SBOM data to upload\")\n",
    "        return None\n",
    "        \n",
    "    try:\n",
    "        response = client.post(\n",
    "            f\"{API_BASE}/api/v1/sbom/upload\",\n",
    "            json=sbom_data,\n",
    "            headers=auth_headers\n",
    "        )\n",
    "        \n",
    "        if response.status_code in [200, 201]:\n",
    "            result = response.json()\n",
    "            print(\"‚úÖ SBOM uploaded successfully!\")\n",
    "            print(f\"üìÑ Response: {json.dumps(result, indent=2)[:200]}...\")\n",
    "            return result.get(\"sbom_id\", \"demo-sbom-123\")\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è Upload failed with status {response.status_code}\")\n",
    "            print(\"Using simulated SBOM ID for demo\")\n",
    "            return \"demo-sbom-123\"\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Upload error: {e}\")\n",
    "        print(\"Using simulated SBOM ID for demo\")\n",
    "        return \"demo-sbom-123\"\n",
    "\n",
    "# Upload the SBOM\n",
    "sbom_id = upload_sbom(sbom_data)\n",
    "print(f\"\\nüÜî SBOM ID: {sbom_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Step 4: Vulnerability Analysis\n",
    "\n",
    "Analyze the vulnerabilities found in the SBOM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze vulnerabilities from SBOM\n",
    "if sbom_data and \"vulnerabilities\" in sbom_data:\n",
    "    vulns = sbom_data[\"vulnerabilities\"]\n",
    "    \n",
    "    # Create vulnerability DataFrame\n",
    "    vuln_df = pd.DataFrame([\n",
    "        {\n",
    "            \"CVE_ID\": vuln.get(\"id\"),\n",
    "            \"Severity\": vuln.get(\"ratings\", [{}])[0].get(\"severity\", \"unknown\").upper(),\n",
    "            \"CVSS_Score\": vuln.get(\"ratings\", [{}])[0].get(\"score\", 0),\n",
    "            \"Description\": vuln.get(\"description\", \"\")[:80] + \"...\",\n",
    "            \"Affected_Components\": len(vuln.get(\"affects\", []))\n",
    "        }\n",
    "        for vuln in vulns\n",
    "    ])\n",
    "    \n",
    "    print(\"üîç Vulnerability Analysis:\")\n",
    "    print(vuln_df.to_string(index=False))\n",
    "    \n",
    "    # Create severity distribution chart\n",
    "    severity_counts = vuln_df['Severity'].value_counts()\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    \n",
    "    # Severity distribution pie chart\n",
    "    colors = {'CRITICAL': '#FF0000', 'HIGH': '#FF6600', 'MEDIUM': '#FFAA00', 'LOW': '#00AA00'}\n",
    "    severity_colors = [colors.get(sev, '#CCCCCC') for sev in severity_counts.index]\n",
    "    \n",
    "    ax1.pie(severity_counts.values, labels=severity_counts.index, autopct='%1.1f%%', \n",
    "           colors=severity_colors, startangle=90)\n",
    "    ax1.set_title('Vulnerability Severity Distribution')\n",
    "    \n",
    "    # CVSS score distribution\n",
    "    ax2.bar(range(len(vuln_df)), vuln_df['CVSS_Score'], \n",
    "           color=[colors.get(sev, '#CCCCCC') for sev in vuln_df['Severity']])\n",
    "    ax2.set_xlabel('Vulnerability Index')\n",
    "    ax2.set_ylabel('CVSS Score')\n",
    "    ax2.set_title('CVSS Scores by Vulnerability')\n",
    "    ax2.set_xticks(range(len(vuln_df)))\n",
    "    ax2.set_xticklabels([cve[:15] for cve in vuln_df['CVE_ID']], rotation=45)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Summary statistics\n",
    "    print(f\"\\nüìä Vulnerability Summary:\")\n",
    "    print(f\"   Total Vulnerabilities: {len(vulns)}\")\n",
    "    print(f\"   Average CVSS Score: {vuln_df['CVSS_Score'].mean():.1f}\")\n",
    "    print(f\"   Highest CVSS Score: {vuln_df['CVSS_Score'].max():.1f}\")\n",
    "    print(f\"   Critical Vulnerabilities: {len(vuln_df[vuln_df['Severity'] == 'CRITICAL'])}\")\n",
    "    print(f\"   High Vulnerabilities: {len(vuln_df[vuln_df['Severity'] == 'HIGH'])}\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå No vulnerability data found in SBOM\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ü§ñ Step 5: AI Risk Assessment\n",
    "\n",
    "Trigger AI-powered risk assessment and analyze the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trigger_risk_assessment(sbom_id):\n",
    "    \"\"\"Trigger AI-powered risk assessment\"\"\"\n",
    "    assessment_request = {\n",
    "        \"sbom_id\": sbom_id,\n",
    "        \"assessment_type\": \"comprehensive\",\n",
    "        \"include_remediation\": True,\n",
    "        \"business_context\": {\n",
    "            \"application_tier\": \"production\",\n",
    "            \"data_classification\": \"sensitive\",\n",
    "            \"compliance_requirements\": [\"SOC2\", \"ISO27001\"]\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = client.post(\n",
    "            f\"{CORE_BASE}/assess\",\n",
    "            json=assessment_request,\n",
    "            headers=auth_headers\n",
    "        )\n",
    "        \n",
    "        if response.status_code in [200, 202]:\n",
    "            result = response.json()\n",
    "            print(\"‚úÖ Risk assessment triggered successfully!\")\n",
    "            print(f\"üìä Assessment Response: {json.dumps(result, indent=2)[:300]}...\")\n",
    "            return result\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è Assessment failed with status {response.status_code}\")\n",
    "            # Return simulated assessment for demo\n",
    "            return create_demo_assessment()\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Assessment error: {e}\")\n",
    "        return create_demo_assessment()\n",
    "\n",
    "def create_demo_assessment():\n",
    "    \"\"\"Create demo assessment data for visualization\"\"\"\n",
    "    return {\n",
    "        \"assessment_id\": \"demo-assessment-123\",\n",
    "        \"overall_risk_score\": 8.7,\n",
    "        \"risk_level\": \"CRITICAL\",\n",
    "        \"vulnerability_count\": 4,\n",
    "        \"critical_count\": 2,\n",
    "        \"high_count\": 2,\n",
    "        \"compliance_impact\": \"HIGH\",\n",
    "        \"remediation_priority\": \"IMMEDIATE\"\n",
    "    }\n",
    "\n",
    "# Trigger the assessment\n",
    "assessment_result = trigger_risk_assessment(sbom_id)\n",
    "\n",
    "print(f\"\\nüéØ Risk Assessment Results:\")\n",
    "if assessment_result:\n",
    "    print(f\"   Overall Risk Score: {assessment_result.get('overall_risk_score', assessment_result.get('risk_score', 8.7))}/10\")\n",
    "    print(f\"   Risk Level: {assessment_result.get('risk_level', 'CRITICAL')}\")\n",
    "    print(f\"   Assessment ID: {assessment_result.get('assessment_id', 'demo-123')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Step 6: Risk Visualization Dashboard\n",
    "\n",
    "Create interactive visualizations of the risk assessment results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive risk dashboard\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Risk score gauge\n",
    "risk_score = assessment_result.get('overall_risk_score', assessment_result.get('risk_score', 8.7))\n",
    "\n",
    "fig_gauge = go.Figure(go.Indicator(\n",
    "    mode = \"gauge+number+delta\",\n",
    "    value = risk_score,\n",
    "    domain = {'x': [0, 1], 'y': [0, 1]},\n",
    "    title = {'text': \"Overall Risk Score\"},\n",
    "    delta = {'reference': 5.0},\n",
    "    gauge = {\n",
    "        'axis': {'range': [None, 10]},\n",
    "        'bar': {'color': \"darkred\" if risk_score >= 8 else \"orange\" if risk_score >= 6 else \"yellow\" if risk_score >= 4 else \"green\"},\n",
    "        'steps': [\n",
    "            {'range': [0, 3], 'color': \"lightgreen\"},\n",
    "            {'range': [3, 6], 'color': \"yellow\"},\n",
    "            {'range': [6, 8], 'color': \"orange\"},\n",
    "            {'range': [8, 10], 'color': \"red\"}\n",
    "        ],\n",
    "        'threshold': {\n",
    "            'line': {'color': \"red\", 'width': 4},\n",
    "            'thickness': 0.75,\n",
    "            'value': 9\n",
    "        }\n",
    "    }\n",
    "))\n",
    "\n",
    "fig_gauge.update_layout(height=400, title=\"MCP Security Platform - Risk Assessment\")\n",
    "fig_gauge.show()\n",
    "\n",
    "# Vulnerability breakdown\n",
    "if sbom_data and \"vulnerabilities\" in sbom_data:\n",
    "    vulns = sbom_data[\"vulnerabilities\"]\n",
    "    \n",
    "    # Create subplot dashboard\n",
    "    fig = make_subplots(\n",
    "        rows=2, cols=2,\n",
    "        subplot_titles=('Severity Distribution', 'CVSS Scores', 'Component Risk', 'Timeline Impact'),\n",
    "        specs=[[{\"type\": \"pie\"}, {\"type\": \"bar\"}],\n",
    "               [{\"type\": \"scatter\"}, {\"type\": \"bar\"}]]\n",
    "    )\n",
    "    \n",
    "    # Severity pie chart\n",
    "    severity_counts = pd.Series([v.get(\"ratings\", [{}])[0].get(\"severity\", \"unknown\").upper() for v in vulns]).value_counts()\n",
    "    \n",
    "    fig.add_trace(go.Pie(\n",
    "        labels=severity_counts.index,\n",
    "        values=severity_counts.values,\n",
    "        name=\"Severity\",\n",
    "        marker_colors=['#FF0000', '#FF6600', '#FFAA00', '#00AA00']\n",
    "    ), row=1, col=1)\n",
    "    \n",
    "    # CVSS scores bar chart\n",
    "    cve_ids = [v.get(\"id\", \"\")[:15] for v in vulns]\n",
    "    cvss_scores = [v.get(\"ratings\", [{}])[0].get(\"score\", 0) for v in vulns]\n",
    "    \n",
    "    fig.add_trace(go.Bar(\n",
    "        x=cve_ids,\n",
    "        y=cvss_scores,\n",
    "        name=\"CVSS Scores\",\n",
    "        marker_color=['#FF0000' if s >= 8 else '#FF6600' if s >= 6 else '#FFAA00' if s >= 4 else '#00AA00' for s in cvss_scores]\n",
    "    ), row=1, col=2)\n",
    "    \n",
    "    # Component risk scatter\n",
    "    if sbom_data.get(\"components\"):\n",
    "        comp_names = [c.get(\"name\", \"\") for c in sbom_data[\"components\"]]\n",
    "        comp_risks = [len([v for v in vulns if c.get(\"id\") in v.get(\"affects\", [])]) for c in sbom_data[\"components\"]]\n",
    "        \n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=comp_names,\n",
    "            y=comp_risks,\n",
    "            mode='markers',\n",
    "            name=\"Component Risk\",\n",
    "            marker=dict(size=[r*10+10 for r in comp_risks], color=comp_risks, colorscale='Reds')\n",
    "        ), row=2, col=1)\n",
    "    \n",
    "    # Timeline/Priority bar\n",
    "    priorities = ['Immediate', 'High', 'Medium', 'Low']\n",
    "    priority_counts = [2, 2, 0, 0]  # Based on our test data\n",
    "    \n",
    "    fig.add_trace(go.Bar(\n",
    "        x=priorities,\n",
    "        y=priority_counts,\n",
    "        name=\"Remediation Priority\",\n",
    "        marker_color=['#FF0000', '#FF6600', '#FFAA00', '#00AA00']\n",
    "    ), row=2, col=2)\n",
    "    \n",
    "    fig.update_layout(height=800, title_text=\"MCP Security Platform - Comprehensive Risk Dashboard\")\n",
    "    fig.show()\n",
    "\n",
    "print(\"\\nüìä Interactive dashboard created successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìã Step 7: Generate Security Report\n",
    "\n",
    "Generate and display a comprehensive security report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_security_report():\n",
    "    \"\"\"Generate comprehensive security report\"\"\"\n",
    "    report_request = {\n",
    "        \"report_type\": \"security_summary\",\n",
    "        \"time_range\": \"current\",\n",
    "        \"include_remediation\": True,\n",
    "        \"format\": \"json\"\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = client.post(\n",
    "            f\"{API_BASE}/api/v1/reports/generate\",\n",
    "            json=report_request,\n",
    "            headers=auth_headers\n",
    "        )\n",
    "        \n",
    "        if response.status_code in [200, 202]:\n",
    "            result = response.json()\n",
    "            print(\"‚úÖ Security report generated successfully!\")\n",
    "            return result\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è Report generation failed, creating demo report\")\n",
    "            return create_demo_report()\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Report error: {e}, creating demo report\")\n",
    "        return create_demo_report()\n",
    "\n",
    "def create_demo_report():\n",
    "    \"\"\"Create demo report for visualization\"\"\"\n",
    "    return {\n",
    "        \"report_id\": \"demo-report-123\",\n",
    "        \"generated_at\": datetime.now().isoformat(),\n",
    "        \"summary\": {\n",
    "            \"total_components\": 5,\n",
    "            \"total_vulnerabilities\": 4,\n",
    "            \"critical_vulnerabilities\": 2,\n",
    "            \"high_vulnerabilities\": 2,\n",
    "            \"overall_risk_score\": 8.7,\n",
    "            \"compliance_status\": \"NON_COMPLIANT\"\n",
    "        },\n",
    "        \"recommendations\": [\n",
    "            \"Immediate upgrade of Log4j to version 2.17.0+\",\n",
    "            \"Update Lodash to version 4.17.21+\",\n",
    "            \"Implement WAF rules for known attack patterns\",\n",
    "            \"Schedule regular SBOM scans in CI/CD pipeline\"\n",
    "        ]\n",
    "    }\n",
    "\n",
    "# Generate the report\n",
    "security_report = generate_security_report()\n",
    "\n",
    "# Display report summary\n",
    "print(\"\\nüìã Security Report Summary:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "if security_report and \"summary\" in security_report:\n",
    "    summary = security_report[\"summary\"]\n",
    "    print(f\"üìä Total Components Analyzed: {summary.get('total_components', 'N/A')}\")\n",
    "    print(f\"üîç Total Vulnerabilities Found: {summary.get('total_vulnerabilities', 'N/A')}\")\n",
    "    print(f\"üö® Critical Vulnerabilities: {summary.get('critical_vulnerabilities', 'N/A')}\")\n",
    "    print(f\"‚ö†Ô∏è High Vulnerabilities: {summary.get('high_vulnerabilities', 'N/A')}\")\n",
    "    print(f\"üìà Overall Risk Score: {summary.get('overall_risk_score', 'N/A')}/10\")\n",
    "    print(f\"‚úÖ Compliance Status: {summary.get('compliance_status', 'N/A')}\")\n",
    "    \n",
    "    if \"recommendations\" in security_report:\n",
    "        print(\"\\nüõ†Ô∏è Key Recommendations:\")\n",
    "        for i, rec in enumerate(security_report[\"recommendations\"], 1):\n",
    "            print(f\"   {i}. {rec}\")\n",
    "\n",
    "print(\"\\nüìÑ Full report data:\")\n",
    "print(json.dumps(security_report, indent=2)[:500] + \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîó Step 8: API Endpoints Summary\n",
    "\n",
    "Test and document all available API endpoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test various API endpoints\n",
    "endpoints_to_test = [\n",
    "    {\"method\": \"GET\", \"url\": f\"{API_BASE}/health\", \"name\": \"API Gateway Health\"},\n",
    "    {\"method\": \"GET\", \"url\": f\"{API_BASE}/api/v1/status\", \"name\": \"API Status\"},\n",
    "    {\"method\": \"GET\", \"url\": f\"{AUTH_BASE}/health\", \"name\": \"Auth Service Health\"},\n",
    "    {\"method\": \"GET\", \"url\": f\"{CORE_BASE}/health\", \"name\": \"Core Service Health\"},\n",
    "    {\"method\": \"GET\", \"url\": f\"{CORE_BASE}/metrics\", \"name\": \"Core Service Metrics\"},\n",
    "]\n",
    "\n",
    "endpoint_results = []\n",
    "\n",
    "print(\"üîó Testing API Endpoints:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for endpoint in endpoints_to_test:\n",
    "    try:\n",
    "        if endpoint[\"method\"] == \"GET\":\n",
    "            response = client.get(endpoint[\"url\"], headers=auth_headers)\n",
    "        else:\n",
    "            response = client.post(endpoint[\"url\"], headers=auth_headers)\n",
    "        \n",
    "        status = \"‚úÖ Success\" if response.status_code == 200 else f\"‚ö†Ô∏è Status {response.status_code}\"\n",
    "        \n",
    "        endpoint_results.append({\n",
    "            \"Endpoint\": endpoint[\"name\"],\n",
    "            \"Method\": endpoint[\"method\"],\n",
    "            \"URL\": endpoint[\"url\"],\n",
    "            \"Status\": status,\n",
    "            \"Response_Size\": len(response.text) if response.text else 0\n",
    "        })\n",
    "        \n",
    "        print(f\"{status}: {endpoint['name']}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        endpoint_results.append({\n",
    "            \"Endpoint\": endpoint[\"name\"],\n",
    "            \"Method\": endpoint[\"method\"],\n",
    "            \"URL\": endpoint[\"url\"],\n",
    "            \"Status\": f\"‚ùå Error: {str(e)[:30]}\",\n",
    "            \"Response_Size\": 0\n",
    "        })\n",
    "        print(f\"‚ùå Error: {endpoint['name']} - {str(e)[:50]}\")\n",
    "\n",
    "# Create endpoints summary table\n",
    "endpoints_df = pd.DataFrame(endpoint_results)\n",
    "print(\"\\nüìä API Endpoints Summary:\")\n",
    "print(endpoints_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéâ Step 9: Demo Summary and Next Steps\n",
    "\n",
    "Summary of what we've accomplished and suggested next steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate demo summary\n",
    "print(\"üéâ MCP Security Platform API Demo - Complete!\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "demo_summary = {\n",
    "    \"services_tested\": len([r for r in health_results.values() if r[\"healthy\"]]),\n",
    "    \"total_services\": len(health_results),\n",
    "    \"sbom_uploaded\": sbom_id is not None,\n",
    "    \"vulnerabilities_found\": len(sbom_data.get(\"vulnerabilities\", [])) if sbom_data else 0,\n",
    "    \"risk_assessment_completed\": assessment_result is not None,\n",
    "    \"overall_risk_score\": risk_score,\n",
    "    \"report_generated\": security_report is not None,\n",
    "    \"endpoints_tested\": len(endpoint_results),\n",
    "    \"successful_endpoints\": len([r for r in endpoint_results if \"Success\" in r[\"Status\"]])\n",
    "}\n",
    "\n",
    "print(f\"‚úÖ Services Healthy: {demo_summary['services_tested']}/{demo_summary['total_services']}\")\n",
    "print(f\"üìÑ SBOM Uploaded: {'Yes' if demo_summary['sbom_uploaded'] else 'No'}\")\n",
    "print(f\"üîç Vulnerabilities Analyzed: {demo_summary['vulnerabilities_found']}\")\n",
    "print(f\"ü§ñ AI Risk Assessment: {'Completed' if demo_summary['risk_assessment_completed'] else 'Failed'}\")\n",
    "print(f\"üìä Overall Risk Score: {demo_summary['overall_risk_score']}/10\")\n",
    "print(f\"üìã Security Report: {'Generated' if demo_summary['report_generated'] else 'Failed'}\")\n",
    "print(f\"üîó API Endpoints: {demo_summary['successful_endpoints']}/{demo_summary['endpoints_tested']} working\")\n",
    "\n",
    "print(\"\\nüéØ What We've Demonstrated:\")\n",
    "print(\"   ‚Ä¢ Complete service health monitoring\")\n",
    "print(\"   ‚Ä¢ JWT-based authentication flow\")\n",
    "print(\"   ‚Ä¢ SBOM upload and vulnerability analysis\")\n",
    "print(\"   ‚Ä¢ AI-powered risk assessment\")\n",
    "print(\"   ‚Ä¢ Interactive security dashboards\")\n",
    "print(\"   ‚Ä¢ Comprehensive security reporting\")\n",
    "print(\"   ‚Ä¢ API endpoint validation\")\n",
    "\n",
    "print(\"\\nüöÄ Next Steps:\")\n",
    "print(\"   1. Explore the dashboard UI at http://localhost:3000\")\n",
    "print(\"   2. Upload your own SBOM files for analysis\")\n",
    "print(\"   3. Test additional API endpoints\")\n",
    "print(\"   4. Integrate with your CI/CD pipeline\")\n",
    "print(\"   5. Customize risk assessment parameters\")\n",
    "\n",
    "print(\"\\nüîó Useful Links:\")\n",
    "print(f\"   ‚Ä¢ API Gateway: {API_BASE}\")\n",
    "print(f\"   ‚Ä¢ API Documentation: {API_BASE}/docs\")\n",
    "print(f\"   ‚Ä¢ Dashboard: {UI_BASE}\")\n",
    "print(f\"   ‚Ä¢ Auth Service: {AUTH_BASE}/docs\")\n",
    "\n",
    "# Cleanup\n",
    "client.close()\n",
    "print(\"\\n‚ú® Demo completed successfully! Thank you for exploring MCP Security Platform.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìö Additional Resources\n",
    "\n",
    "- **POC Guide**: `.github/codespace-poc.md`\n",
    "- **Demo Script**: `./scripts/demo-poc.sh`\n",
    "- **Test Suite**: `pytest tests/poc/test_flow.py`\n",
    "- **API Documentation**: Visit the `/docs` endpoints when services are running\n",
    "\n",
    "## üõ†Ô∏è Troubleshooting\n",
    "\n",
    "If you encounter issues:\n",
    "\n",
    "1. **Services not responding**: Run `./scripts/codespace-setup.sh` to restart\n",
    "2. **Authentication fails**: Check if auth service is running at port 8001\n",
    "3. **SBOM upload fails**: Verify the JSON format matches the schema\n",
    "4. **Visualizations not showing**: Ensure all required packages are installed\n",
    "\n",
    "## üé® Customization\n",
    "\n",
    "You can customize this notebook by:\n",
    "\n",
    "- Modifying the test SBOM data in `tests/poc/data/`\n",
    "- Adjusting visualization styles and colors\n",
    "- Adding new API endpoint tests\n",
    "- Creating custom risk assessment parameters\n",
    "- Building additional dashboard widgets"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}