"""
Vulnerability Service

Core service for vulnerability analysis operations.
"""

import asyncio
import uuid
from datetime import datetime, timedelta
from typing import Dict, List, Optional

import structlog
from shared.event_bus import EventBus

from ..models.analysis_models import (
    AnalysisRequest, AnalysisResult, AnalysisStatus, AnalysisType,
    AnalysisStatistics
)

logger = structlog.get_logger(__name__)


class VulnerabilityService:
    """
    Core service for vulnerability analysis operations.
    """
    
    def __init__(self, event_bus: EventBus):
        """Initialize the vulnerability service."""
        self.event_bus = event_bus
        
        # Analysis storage
        self.analyses: Dict[str, AnalysisResult] = {}
        self.active_analyses: Dict[str, asyncio.Task] = {}
        
        # Statistics
        self.analysis_count = 0
        self.completed_count = 0
        self.failed_count = 0
        self.total_processing_time = 0.0
        
        # Health status
        self.healthy = True
    
    async def initialize(self):
        """Initialize the service."""
        try:
            self.healthy = True
            logger.info("Vulnerability service initialized")
            
        except Exception as e:
            logger.error("Failed to initialize vulnerability service", error=str(e))
            self.healthy = False
            raise
    
    async def cleanup(self):
        """Cleanup service resources."""
        try:
            # Cancel active analyses
            for analysis_id, task in self.active_analyses.items():
                task.cancel()
                logger.info("Cancelled active analysis", analysis_id=analysis_id)
            
            # Wait for tasks to complete
            if self.active_analyses:
                await asyncio.gather(*self.active_analyses.values(), return_exceptions=True)
            
            self.healthy = False
            logger.info("Vulnerability service cleaned up")
            
        except Exception as e:
            logger.error("Error during vulnerability service cleanup", error=str(e))
    
    def is_healthy(self) -> bool:
        """Check if service is healthy."""
        return self.healthy
    
    async def start_analysis(self, request: AnalysisRequest) -> str:
        """Start a new vulnerability analysis."""
        analysis_id = str(uuid.uuid4())
        
        # Create analysis result record
        analysis = AnalysisResult(
            analysis_id=analysis_id,
            target=request.target,
            status=AnalysisStatus.PENDING,
            analysis_types=request.analysis_types,
            created_at=datetime.utcnow(),
            message="Analysis queued for execution"
        )
        
        self.analyses[analysis_id] = analysis
        self.analysis_count += 1
        
        logger.info("Analysis created", analysis_id=analysis_id, target=request.target)
        return analysis_id
    
    async def execute_analysis(self, analysis_id: str):
        """Execute a vulnerability analysis."""
        if analysis_id not in self.analyses:
            logger.error("Analysis not found", analysis_id=analysis_id)
            return
        
        analysis = self.analyses[analysis_id]
        
        try:
            # Update status
            analysis.status = AnalysisStatus.RUNNING
            analysis.started_at = datetime.utcnow()
            analysis.message = "Analysis in progress"
            
            logger.info("Starting analysis execution", 
                       analysis_id=analysis_id, 
                       target=analysis.target)
            
            # Simulate analysis processing
            await asyncio.sleep(3)
            
            # Generate sample results
            analysis.total_vulnerabilities = 15
            analysis.severity_distribution = {
                "critical": 2,
                "high": 5,
                "medium": 6,
                "low": 2
            }
            analysis.key_findings = [
                "High concentration of critical vulnerabilities in authentication components",
                "Increasing trend in dependency-related vulnerabilities",
                "Several vulnerabilities lack available patches"
            ]
            analysis.recommendations = [
                "Prioritize patching of critical authentication vulnerabilities",
                "Implement dependency scanning in CI/CD pipeline",
                "Consider alternative packages for components without patches"
            ]
            
            # Update final status
            analysis.status = AnalysisStatus.COMPLETED
            analysis.completed_at = datetime.utcnow()
            analysis.duration = (analysis.completed_at - analysis.started_at).total_seconds()
            analysis.message = "Analysis completed successfully"
            
            # Update statistics
            self.completed_count += 1
            self.total_processing_time += analysis.duration
            
            logger.info("Analysis completed", 
                       analysis_id=analysis_id,
                       duration=analysis.duration,
                       vulnerabilities=analysis.total_vulnerabilities)
            
        except asyncio.CancelledError:
            analysis.status = AnalysisStatus.CANCELLED
            analysis.completed_at = datetime.utcnow()
            analysis.message = "Analysis cancelled"
            logger.info("Analysis cancelled", analysis_id=analysis_id)
            
        except Exception as e:
            analysis.status = AnalysisStatus.FAILED
            analysis.completed_at = datetime.utcnow()
            analysis.error_message = str(e)
            analysis.message = f"Analysis failed: {str(e)}"
            self.failed_count += 1
            
            logger.error("Analysis failed", analysis_id=analysis_id, error=str(e))
        
        finally:
            # Remove from active analyses
            if analysis_id in self.active_analyses:
                del self.active_analyses[analysis_id]
    
    async def get_analysis_result(self, analysis_id: str) -> Optional[AnalysisResult]:
        """Get analysis result by ID."""
        return self.analyses.get(analysis_id)
    
    async def analyze_scan_results(self, scan_id: str):
        """Analyze scan results from scanner manager."""
        try:
            # Create automatic analysis request
            request = AnalysisRequest(
                target=f"scan-{scan_id}",
                analysis_types=[AnalysisType.TREND_ANALYSIS, AnalysisType.RISK_ASSESSMENT]
            )
            
            analysis_id = await self.start_analysis(request)
            
            # Start analysis in background
            task = asyncio.create_task(self.execute_analysis(analysis_id))
            self.active_analyses[analysis_id] = task
            
            logger.info("Started automatic analysis for scan", 
                       scan_id=scan_id, analysis_id=analysis_id)
            
        except Exception as e:
            logger.error("Failed to analyze scan results", scan_id=scan_id, error=str(e))
    
    def get_active_analysis_count(self) -> int:
        """Get count of active analyses."""
        return len(self.active_analyses)
    
    def get_completed_analysis_count(self) -> int:
        """Get count of completed analyses."""
        return self.completed_count
    
    async def get_statistics(self) -> AnalysisStatistics:
        """Get service statistics."""
        return AnalysisStatistics(
            total_analyses=self.analysis_count,
            active_analyses=len(self.active_analyses),
            completed_analyses=self.completed_count,
            failed_analyses=self.failed_count,
            average_duration=self.total_processing_time / max(self.completed_count, 1),
            total_processing_time=self.total_processing_time,
            analysis_type_counts={},  # Would calculate from actual data
            analyses_last_24h=0,  # Would calculate from timestamps
            analyses_last_week=0,  # Would calculate from timestamps
            cpu_usage=0.0,  # Would get from system monitoring
            memory_usage=0.0,  # Would get from system monitoring
            generated_at=datetime.utcnow()
        )